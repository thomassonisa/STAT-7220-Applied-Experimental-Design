{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "62032799",
      "metadata": {
        "id": "62032799"
      },
      "source": [
        "# Intro to Python Programming for Data Science\n",
        "## Dr Austin R Brown\n",
        "## School of Data Science and Analytics\n",
        "### Kennesaw State University"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1452b8fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1452b8fe",
        "outputId": "34e2e131-9736-401f-cecd-5639612e67ad"
      },
      "outputs": [],
      "source": [
        "# === COURSE REPO SETUP === #\n",
        "\n",
        "# 1. ENTER your GitHub username (the one that owns your fork)\n",
        "#github_username = \"abrown9008\"\n",
        "\n",
        "# 2. Name of the repo (don't change unless your fork name is different)\n",
        "repo_name = \"STAT-7220-Applied-Experimental-Design\"\n",
        "\n",
        "# 3. Build the full repo URL for cloning\n",
        "repo_url = f\"https://github.com/{github_username}/{repo_name}.git\"\n",
        "\n",
        "import os\n",
        "\n",
        "# --- Detect if we're already in a repo ---\n",
        "cwd = os.getcwd()\n",
        "if cwd.endswith(repo_name):\n",
        "    print(f\"‚úÖ Already inside repo folder: {cwd}\")\n",
        "else:\n",
        "    # --- If the repo folder exists, check if it's nested ---\n",
        "    if os.path.exists(repo_name):\n",
        "        print(f\"‚ö†Ô∏è Found existing folder '{repo_name}'. Skipping clone to avoid nesting.\")\n",
        "    else:\n",
        "        print(f\"üì• Cloning repo from {repo_url}...\")\n",
        "        os.system(f\"git clone {repo_url}\")\n",
        "\n",
        "    # --- Change to repo directory ---\n",
        "    if os.path.exists(repo_name):\n",
        "        os.chdir(repo_name)\n",
        "        print(f\"üìÇ Changed directory to: {os.getcwd()}\")\n",
        "    else:\n",
        "        print(\"‚ùå ERROR: Repo folder not found. Please check your GitHub username.\")\n",
        "\n",
        "# --- Check if this is the instructor's repo instead of student's fork ---\n",
        "# This command needs to be run from within the repository directory\n",
        "remote_url = os.popen(\"git config --get remote.origin.url\").read().strip()\n",
        "\n",
        "if \"abrown9008\" in remote_url:\n",
        "    print(\"‚ö†Ô∏è WARNING: You are working in the instructor's repo, not your fork!\")\n",
        "    print(\"üí° Please fork the repo to your own account and update `github_username` above.\")\n",
        "else:\n",
        "    print(f\"üîó Connected to fork at: {remote_url}\")\n",
        "\n",
        "# Set Today's Directory #\n",
        "\n",
        "today_dir = \"Python for Data Science\"\n",
        "os.chdir(today_dir)\n",
        "print(f\"üìÇ Changed directory to: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85b694cd",
      "metadata": {},
      "source": [
        "\n",
        "- When we think about statistics and data science, very often our minds go straight to the analysis of data.\n",
        "\n",
        "- However, being able to effectively answer questions with data requires a systematic, well-thought-out approach.\n",
        "    - The analysis is only part of it!\n",
        "\n",
        "- For us, the scientific method lays out a nice framework that we can use to guide our thinking.\n",
        "\n",
        "### The Scientific Method\n",
        "\n",
        "- Remember from high school science class that the scientific method generally involves:\n",
        "    1. Making a hypothesis about some phenomenon\n",
        "        - This includes defining our independent (features) and dependent (targets) variables\n",
        "    2. Collecting data to test the hypothesis\n",
        "    3. Analyzing the data\n",
        "    4. Drawing conclusions from the data\n",
        "    5. Refining the hypothesis and repeating the process\n",
        "\n",
        "- Even if we aren't working in laboratory sciences, this systematic approach helps us make sure we're using the right data to answer the right question.\n",
        "\n",
        "- I like to call working through steps 1 - 5 of the scientific method a **study**.\n",
        "\n",
        "### Types of Studies\n",
        "\n",
        "- Generally speaking, we can classify studies into two categories:\n",
        "    1. **Observational Studies**\n",
        "    2. **Experimental Studies**\n",
        "\n",
        "- In an **observational study**, we are simply observing our independent and dependent variables. We don't have control over how observational units get assigned to specific values of either the independent or dependent variables.\n",
        "\n",
        "#### Observational Study Example\n",
        "\n",
        "- For example, suppose I wanted to know if the mean annual income differs between undergraduate data science majors and psychology majors.\n",
        "\n",
        "- In this case, mean annual income serves as my quantitative dependent (or outcome) variable and major (data science or psychology) serves as my categorical independent (or predictor/explanatory) variable.\n",
        "\n",
        "- I as the researcher in this case don't have control over whether students are data science or psychology majors -- I'm simply observing a phenomenon.\n",
        "    - So this study would be classified as an *observational* study.\n",
        "\n",
        "- Let's contrast this with an experimental study.\n",
        "\n",
        "#### Experimental Study Example\n",
        "\n",
        "- Let's say you work for a marketing department in a retail company. We have an email list of 10,000 customers.\n",
        "\n",
        "- We want to test the impact of two different email subject lines (e.g., a generic subject line and a personalized subject line) on annual spending with our company.\n",
        "\n",
        "- In this case, we could randomly assign our customers to either the generic subject line group or the personalized subject line group and follow their spending over the course of a year before making a comparison.\n",
        "\n",
        "- Email group serves as our categorical independent variable and annual spending serves as our quantitative outcome variable.\n",
        "\n",
        "- But notice in this case, we the researcher assigned the participants to their respective groups.\n",
        "    - This is the key difference between observational and experimental research.\n",
        "\n",
        "### Why Should I Care About Experimentation?\n",
        "\n",
        "- While we may often associate experiments with laboratory science, experimental design is actually very helpful in a variety of fields including:\n",
        "    1.  Engineering\n",
        "    2.  Manufacturing/Quality Control\n",
        "    3.  Marketing\n",
        "    4.  Social Science\n",
        "    5.  Educational Research\n",
        "    6.  Much more!\n",
        "\n",
        "- The roots of DOE (design of experiments) go back to Fisher himself as he aimed to study crop yields.\n",
        "\n",
        "- Over the course of the semester, you will see how DOE is important to:\n",
        "\n",
        "- **Informed Decision-Making**: It provides a structured approach to testing hypotheses, allowing people/organizations to make data-driven decisions based on reliable evidence.\n",
        "\n",
        "- **Resource Optimization**: By identifying what works and what doesn't, people/organizations can allocate their resources more efficiently, avoiding wasted time and money on ineffective strategies.\n",
        "\n",
        "- **Process Improvement**: Well-designed experiments can uncover insights that lead to innovative solutions and improvements, which may serve as a competitive advantage in a business setting.\n",
        "\n",
        "### Definitions\n",
        "\n",
        "- Before we go much further, it may be helpful if we have some agreed upon definitions (so we're speaking the same language!)\n",
        "\n",
        "- Note, if there is ever a time when a term is used in these slides or elsewhere that doesn't seem well-defined, **PLEASE ASK FOR GUIDANCE!!**\n",
        "\n",
        "- **Experiment (or Run)**: an action where the experimenter changes at least one of the variables being studied and then observes the effect of the action.\n",
        "    - Randomizing our customers into the generic and personalized email groups and then observing their purchasing behavior was an experiment.\n",
        "\n",
        "\n",
        "- **Experimental Unit**: the item under study upon which something is changed. This could be raw materials, human subjects, or just a point in time.\n",
        "    - Our individual customers in the marketing example were our experimental units.\n",
        "\n",
        "- **Independent Variable (Factor or Treatment Factor or Feature)**: We generally think of this as the $X$ variable that is being controlled at some level during any given experiment.\n",
        "    - Email group from the prior example\n",
        "\n",
        "- **Lurking Variable (Background Variable)**: a variable that the experimenter is unaware of or cannot control which could have an effect on the outcome of the experiment.\n",
        "    - In the email example, annual income probably plays a role in annual spending. This isn't something the marketing department can control.\n",
        "\n",
        "- **Dependent Variable (or Response or Outcome or Target)**: Usually denoted $Y$, this is the characteristic of the experimental unit that is measured after each experiment/run.\n",
        "\n",
        "- **Effect**: The change in the response that is caused by a change in a factor/independent variable.\n",
        "\n",
        "- These definitions will get us started, but there will be more new terms added as we progress through the semester!\n",
        "\n",
        "### Planning Experiments\n",
        "\n",
        "- The key to successful experiments (and studies in general really) is a very clear articulation about what you're studying, why you're studying it, how you're studying it, and how you'll draw conclusions from the experiment(s).\n",
        "\n",
        "- More specifically: \n",
        "    - **(1)** Define the objective \n",
        "    - **(2)** Decide what the outcome is (and how it will be measured) \n",
        "    - **(3)** Determine the independent variables and possible lurking variables\n",
        "    - **(4)** Choose the design (more on this as the semester progresses) \n",
        "    - **(5)** Be clear on data collection processes/procedures \n",
        "    - **(6)** Be clear on which analyses will be performed and how they are appropriate for the objective and design\n",
        "    - **(7)** Draw conclusions\n",
        "\n",
        "- As the semester progresses, we will systematically go through each of these steps in every lecture, example, and assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace21525",
      "metadata": {
        "id": "ace21525"
      },
      "source": [
        "## Why Learn Python?  \n",
        "- You may be asking yourself, out of all of the possible programming languages which exist, why should I spend time learning Python?\n",
        "\n",
        "- Great question!\n",
        "\n",
        "- Python is a useful tool and worthwhile to learn for several reasons:\n",
        "    1. It's free!\n",
        "    2. Because it's open source, thousands of people have contributed packages and functions at a pace that proprietary softwares can't compete with\n",
        "    3. It is a very flexible and robust general programming language, meaning there's a lot you can do with it in the data science space and beyond!\n",
        "    4. It has become basically the standard in industry\n",
        "\n",
        "## So What is Python?\n",
        "\n",
        "- Python is command-line, object-oriented general programming language commonly used for data analysis, data science and statistics.\n",
        "\n",
        "- **Command-line** means that we have to give it commands in order for us to get it to do something. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4a011d3c",
      "metadata": {
        "id": "4a011d3c",
        "outputId": "c5efcf38-8ec4-42a5-dc32-886d29cc3401"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## What is the sum of 2 & 3? ##\n",
        "2 + 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e1b5db",
      "metadata": {
        "id": "00e1b5db"
      },
      "source": [
        "**Object-oriented** means that we can save individual pieces of output as some name that we can use later. This is a super handy feature, especially when you have complicated scripts! For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1f97bae9",
      "metadata": {
        "id": "1f97bae9",
        "outputId": "8f770594-4892-45f8-847a-abd5e28144f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "## Save 2 + 3 as \"a\" ##\n",
        "a = 2 + 3\n",
        "print(a)\n",
        "print(a*2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c203d1",
      "metadata": {
        "id": "b1c203d1"
      },
      "source": [
        "## What Can Python do?\n",
        "\n",
        "- What can Python do? Well, for the purpose of data analytics, I have yet to find a limit!\n",
        "\n",
        "- In this class, we will be learning how to use Python as a tool in the data science workflow with specific attention placed on designing and evaluating experiments (more on that in the first week's lecture!)\n",
        "\n",
        "- What is the data science workflow? Let's take a look!\n",
        "\n",
        "![From R for Data Science 2nd Edition](https://github.com/abrown9008/STAT-7220-Applied-Experimental-Design/blob/main/Python%20for%20Data%20Science/Data%20Science%20Workflow.png?raw=1)\n",
        "\n",
        "## Importing Data/Data Loading\n",
        "\n",
        "- Since a major reason we use Python is for the analysis of data, we need to know how to import/load data from various sources and file formats into our Python programming environment.\n",
        "\n",
        "- There are a variety of ways of importing data into our Python programming environment, which largely depend on the type of datafile that you are importing (e.g., Excel file, CSV file, text file, SAS dataset, SPSS dataset, etc.).\n",
        "\n",
        "- While there are lots of different files which can be imported into our Python programming environment (Google/GenAI is an excellent resource for searching for code for how to start to do something), we're going to focus on two main types: Excel and CSV\n",
        "\n",
        "- For example, let's try importing a CSV file using Python. This file is part of the famous Framingham Heart Study and is called `HEART.csv` and is located in the `Python for Data Science` subfolder that's part of our class GitHub repo.\n",
        "\n",
        "- To read in this CSV file using Python, we will use the `read_csv` function, which is part of the famous `pandas` package.\n",
        "\n",
        "### Defining Packages and Functions\n",
        "\n",
        "- Okay, but before we get into reading in the `HEART` CSV file, what in the world is a package and function??\n",
        "\n",
        "- We can think of packages like toolboxes in a mechanic's shop. Each toolbox contains different tools used for specific purposes.\n",
        "\n",
        "- To access a particular tool, we have to go to the right toolbox.\n",
        "    - A toolbox is like a package\n",
        "    - The tools within the toolbox are like functions within a package\n",
        "\n",
        "- Thus, `read_csv` is a tool (function) within the `pandas` toolbox (package).\n",
        "\n",
        "- A function can also be thought of like a mathematical function: we provide some input and some specific output is returned. Now, while our Python programming enviroment comes with some functions pre-loaded, almost all others in existence have to be installed from the web, including `pandas`.\n",
        "\n",
        "- To install a Python package, we have to use a particular command line function called `pip` which is a recursive acroymn for \"pip installs packages\".\n",
        "    - In brief, `pip` is a package management system used to install and manage software packages written in Python.\n",
        "\n",
        "- Since we need `pandas` to load the `HEART.csv` file, we can install by using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ea6486b8",
      "metadata": {
        "id": "ea6486b8"
      },
      "outputs": [],
      "source": [
        "## Install pandas using pip ##\n",
        "## Remove the # to the left of %pip\n",
        "## before executing the code ##\n",
        "\n",
        "#%pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a81cb4",
      "metadata": {
        "id": "51a81cb4"
      },
      "source": [
        "- Now, we can load the `pandas` library into our current Python environment by using the `import` function. Note, to access the functions within a package, we have to use the following code syntax: `package_name.function_name`\n",
        "\n",
        "- So typically when we import a package, we shorten its name to something to allow for brevity in our code.\n",
        "    - `pandas` is almost universally imported as `pd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "51e3e139",
      "metadata": {
        "id": "51e3e139",
        "outputId": "cfb507ef-dadb-4008-c8d4-39fcf7cf74f4"
      },
      "outputs": [],
      "source": [
        "## Load pandas library ##\n",
        "import pandas as pd\n",
        "\n",
        "## Load HEART CSV ##\n",
        "heart = pd.read_csv(\"HEART.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3386bc2d",
      "metadata": {
        "id": "3386bc2d"
      },
      "source": [
        "- Awesome! Now that we've loaded the `heart` dataframe, how do we know that it loaded correctly?\n",
        "\n",
        "- There are two general approaches I'd recommend. One is a simple overview of the first few rows of the dataframe which we can obtain via the `.head` function.\n",
        "\n",
        "- The second is by using the `.info` function. This is equivalent to `dplyr::glimpse` in R or `PROC CONTENTS` in SAS.\n",
        "    - Let's check out how we'd use both techniques here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16b8d5e2",
      "metadata": {
        "id": "16b8d5e2",
        "outputId": "a760505a-52f7-4994-a877-144fc0454216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5209, 17)\n"
          ]
        }
      ],
      "source": [
        "## First, what are the number of rows\n",
        "## and columns in the dataframe?\n",
        "## Let's use the .shape function! ##\n",
        "\n",
        "print(heart.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe8deb7",
      "metadata": {
        "id": "cfe8deb7"
      },
      "source": [
        "- Nice! So we know we have 5209 rows (or observations) and 17 columns (or variables).\n",
        "\n",
        "- Now let's check out the techniques for inspecting the dataframe!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "70b90a76",
      "metadata": {
        "id": "70b90a76",
        "outputId": "0eb76423-08a3-48b6-9ffd-e6f63adbbc92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Status DeathCause  AgeCHDdiag     Sex  AgeAtStart  Height  Weight  \\\n",
            "0   Dead      Other         NaN  Female          29   62.50   140.0   \n",
            "1   Dead     Cancer         NaN  Female          41   59.75   194.0   \n",
            "2  Alive        NaN         NaN  Female          57   62.25   132.0   \n",
            "3  Alive        NaN         NaN  Female          39   65.75   158.0   \n",
            "4  Alive        NaN         NaN    Male          42   66.00   156.0   \n",
            "\n",
            "   Diastolic  Systolic    MRW  Smoking  AgeAtDeath  Cholesterol Chol_Status  \\\n",
            "0         78       124  121.0      0.0        55.0          NaN         NaN   \n",
            "1         92       144  183.0      0.0        57.0        181.0   Desirable   \n",
            "2         90       170  114.0     10.0         NaN        250.0        High   \n",
            "3         80       128  123.0      0.0         NaN        242.0        High   \n",
            "4         76       110  116.0     20.0         NaN        281.0        High   \n",
            "\n",
            "  BP_Status Weight_Status   Smoking_Status  \n",
            "0    Normal    Overweight       Non-smoker  \n",
            "1      High    Overweight       Non-smoker  \n",
            "2      High    Overweight  Moderate (6-15)  \n",
            "3    Normal    Overweight       Non-smoker  \n",
            "4   Optimal    Overweight    Heavy (16-25)  \n"
          ]
        }
      ],
      "source": [
        "## .head method ##\n",
        "\n",
        "print(heart.head(n=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414e401e",
      "metadata": {
        "id": "414e401e"
      },
      "source": [
        "- With `.head`, we can see that the variable `Sex`, for example, is a *categorical* variable, meaning that it's values are qualities (e.g., `Male` or `Female`).\n",
        "\n",
        "- On the other hand, `Height`, seems to be measured with numbers likely implying that it is a *quantitative* variable.\n",
        "    - We can use `.info` and the `pyjanitor` package to confirm this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d32ece25",
      "metadata": {
        "id": "d32ece25",
        "outputId": "0d89a0a9-911e-46d5-f784-2b750d2f4777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5209 entries, 0 to 5208\n",
            "Data columns (total 17 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Status          5209 non-null   object \n",
            " 1   DeathCause      1991 non-null   object \n",
            " 2   AgeCHDdiag      1449 non-null   float64\n",
            " 3   Sex             5209 non-null   object \n",
            " 4   AgeAtStart      5209 non-null   int64  \n",
            " 5   Height          5203 non-null   float64\n",
            " 6   Weight          5203 non-null   float64\n",
            " 7   Diastolic       5209 non-null   int64  \n",
            " 8   Systolic        5209 non-null   int64  \n",
            " 9   MRW             5203 non-null   float64\n",
            " 10  Smoking         5173 non-null   float64\n",
            " 11  AgeAtDeath      1991 non-null   float64\n",
            " 12  Cholesterol     5057 non-null   float64\n",
            " 13  Chol_Status     5057 non-null   object \n",
            " 14  BP_Status       5209 non-null   object \n",
            " 15  Weight_Status   5203 non-null   object \n",
            " 16  Smoking_Status  5173 non-null   object \n",
            "dtypes: float64(7), int64(3), object(7)\n",
            "memory usage: 691.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "## .info method ##\n",
        "\n",
        "print(heart.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5389521b",
      "metadata": {
        "id": "5389521b"
      },
      "source": [
        "- In this output, look again at the `Sex` variable. We see that it has 5209 non-null (non-missing) values, meaning that for every row in the dataframe, we have a valid, non-missing value!\n",
        "\n",
        "- Then next to this information, we can see that its datatype is `object`. This is Python's naming convention for a nominal, categorical variable.\n",
        "\n",
        "- For `Height`, we see that is has 6 missing values ($5209 - 5203 = 6$). We also see that Python considers it `float64`. This is Python's naming convention for a continuous, quantitative variable.\n",
        "    - Notice that `AgeAtStart` is considered `int64`. This is an integer, or discrete, quantitative variable designation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49072e9",
      "metadata": {
        "id": "f49072e9"
      },
      "source": [
        "## Working with Dataframes\n",
        "\n",
        "- Let's say I wanted to find the average or mean of the `AgeAtStart` column from the `heart` dataframe. How would I go about doing that?\n",
        "\n",
        "- First, I need to know how to refer to that single variable by itself.\n",
        "\n",
        "- To do this, we make use of the square bracket notation. Specifically, we can call a single column within a dataframe by using the following syntax: `df['Variable_Name']`.\n",
        "\n",
        "- You can think of the square bracket like a door to your home. The name of the dataframe is the house itself, the brackets are the door, and the variable name is the person we want to talk to inside of the house.\n",
        "    - So the structure is `house['Person']`.\n",
        "\n",
        "- If we run the following command, let's see what happens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8eb118a1",
      "metadata": {
        "id": "8eb118a1",
        "outputId": "c3a35caf-ce76-4c1f-d794-a5d4f807b4a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       29\n",
            "1       41\n",
            "2       57\n",
            "3       39\n",
            "4       42\n",
            "        ..\n",
            "5204    49\n",
            "5205    42\n",
            "5206    51\n",
            "5207    36\n",
            "5208    36\n",
            "Name: AgeAtStart, Length: 5209, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## house[\"Person\"] ##\n",
        "\n",
        "print(heart['AgeAtStart'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd58c672",
      "metadata": {
        "id": "dd58c672"
      },
      "source": [
        "- If we go back and look at the output of the `.head` function, we can see that the values in this output vector correspond to the output we had from that function as well.\n",
        "\n",
        "- Note, the first element in Python (and many other programming languages) is coded as 0 rather than 1. There are some historical reasons for this but it ends up serving convenience purposes in some operations (i.e., range and length calculations) as well.\n",
        "\n",
        "- Okay so now that we've established how to directly refer to a variable within a dataframe, how do we calculate the mean? Here, we are going to use the popular `numpy` package to help us out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f084455a",
      "metadata": {
        "id": "f084455a",
        "outputId": "18f07068-7e6c-46b6-e1aa-739d319039bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44.07\n"
          ]
        }
      ],
      "source": [
        "## Install numpy. Remember\n",
        "## to remove # from the left\n",
        "## of the following line of\n",
        "## code before executing ##\n",
        "\n",
        "#%pip install numpy\n",
        "\n",
        "## Load numpy ##\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "## Calculate Mean AgeAtStart ##\n",
        "\n",
        "print(round(\n",
        "    np.mean(heart['AgeAtStart']),\n",
        "    2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a95625ee",
      "metadata": {
        "id": "a95625ee"
      },
      "source": [
        "- So the mean age at start is 44.07 years old!\n",
        "\n",
        "## Tidying Data\n",
        "\n",
        "### Selecting Columns\n",
        "\n",
        "- Now, let's say I have a large dataframe with lots of columns of information, as you might see in your own careers.\n",
        "\n",
        "- But, for whatever analysis I'm wanting to do, I don't need all of the columns, just a few.\n",
        "\n",
        "- In such a case, it might be useful to subset the dataframe and select only the columns we need.\n",
        "\n",
        "- How do we go about doing this? Like many things in Python, there are a few different ways to yield the same result, but I'm going to show you what I consider the most straightforward method, which uses the `house[\"Person\"]` syntax we worked with previously.\n",
        "\n",
        "- Let's say using the `heart` dataframe, I want to create a new dataframe which only contains the last four columns: `Chol_Status`, `BP_Status`, `Weight_Status`, and `Smoking_Status`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f1f80e4f",
      "metadata": {
        "id": "f1f80e4f",
        "outputId": "9f0d245b-5810-414d-afe5-2d3c08bfacfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5209 entries, 0 to 5208\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Chol_Status     5057 non-null   object\n",
            " 1   BP_Status       5209 non-null   object\n",
            " 2   Weight_Status   5203 non-null   object\n",
            " 3   Smoking_Status  5173 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 162.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "## Creat New Dataframe using subset of\n",
        "## columns ##\n",
        "\n",
        "heart1 = heart[['Chol_Status',\n",
        "                'BP_Status',\n",
        "                'Weight_Status',\n",
        "                'Smoking_Status']]\n",
        "\n",
        "print(heart1.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a348490",
      "metadata": {
        "id": "1a348490"
      },
      "source": [
        "- We can see that the column selection worked because we have the same number of rows (5209) but now only those four columns we specified.\n",
        "\n",
        "### Filtering Rows\n",
        "\n",
        "- We just learned how to subset columns. What if we wanted to subset by values in the rows?\n",
        "\n",
        "- For example, let's say in the new `heart1` dataframe we just created, we want to create a new dataframe where we only have those participants whose `Weight_Status` is \"Overweight.\"\n",
        "\n",
        "- Again, there are a few different approaches, but I would recommend using what we've learned so far with the `house['Person']` syntax.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "421a2b96",
      "metadata": {
        "id": "421a2b96",
        "outputId": "b6bec34d-aabf-4d25-c48a-6cc49e65043e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3550, 4)\n"
          ]
        }
      ],
      "source": [
        "## Create new dataframe from heart1\n",
        "## where participants' Weight_Status == \"Overweight\" ##\n",
        "\n",
        "heart2 = heart1[heart1['Weight_Status'] == \"Overweight\"]\n",
        "\n",
        "print(heart2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72a9b45a",
      "metadata": {
        "id": "72a9b45a"
      },
      "source": [
        "- Here we can see that the number of columns is the same (4) but now the number of rows is smaller than the total number in the `heart1` dataframe.\n",
        "    - How can we confirm that the filtering worked correctly?\n",
        "\n",
        "- One strategy is by counting up the number of participants in the `heart1` dataframe whose `Weight_Status` was considered \"Overweight\".\n",
        "\n",
        "- If that number matches the number of rows in `heart2`, then we can feel confident that the filtering worked the way we expected it to.\n",
        "    - Let's try using the `.value_counts` function to check our work!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "97afb0a1",
      "metadata": {
        "id": "97afb0a1",
        "outputId": "d44da93c-48f9-4165-c099-d79e71d3205b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight_Status\n",
            "Overweight     3550\n",
            "Normal         1472\n",
            "Underweight     181\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Tabulate Number of Overweight Participants\n",
        "## in heart1 dataframe ##\n",
        "\n",
        "print(heart1['Weight_Status'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742d3057",
      "metadata": {
        "id": "742d3057"
      },
      "source": [
        "- Since the number of Overweight participants in `heart1` (3550) is equal to the number of rows in `heart2`, we can feel confident our filtering worked the way we anticipated!\n",
        "\n",
        "## What is \"Tidy\" Data?\n",
        "\n",
        "- Once we have imported data, our next job is often to \"tidy\" it. Tidy data refers to data structure or how information is stored.\n",
        "\n",
        "- A tidy dataframe has the following characteristics:\n",
        "    1. Each variable is a column; each column is a variable.\n",
        "    2. Each observation is a row; each row is an observation.\n",
        "    3. Each value has is a cell; each cell is a single value.\n",
        "\n",
        "![From R for Data Science 2nd Edition](https://github.com/abrown9008/STAT-7220-Applied-Experimental-Design/blob/main/Python%20for%20Data%20Science/Tidy%20Data%20Structure.png?raw=1)\n",
        "\n",
        "- Why should we care about having our data in tidy format? There are two key reasons:\n",
        "\n",
        "- First, consistency. It's much easier to work with datasets if we know what format they're in.\n",
        "\n",
        "- Second, this is generally the structure most Python functions want the data to be in to work correctly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
